# -*- coding: utf-8 -*-
"""Project2-Diabetes Prediction .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1os0WPSeLZ6Uf0P0b-azMqb-_QFpGofCo
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score

"""Data Collection Part and Analysis
PIMA Diabetes Dataset


"""

#loading the diabetes dataset through pandas dataframe
#comma separated values
diabetes_dataset=pd.read_csv('/content/diabetes (1).csv')

pd.read_csv?
#functions and parameters seen using ?

#first 5 cells of female dataset
diabetes_dataset.head()

#number of rows and columns in this dataset
diabetes_dataset.shape

#getting the statistical measures of the data
diabetes_dataset.describe()

diabetes_dataset['Outcome'].value_counts()
#tells how many for label 0 non diabetic and 1 for diabetic 
#as dataset small non diabetic data is there more generally we use dataset as 1lakh etc.

diabetes_dataset.groupby('Outcome').mean()

#as above table diabetic people have more glucose level in their blood 
#seaparate data and labels outcome is droped and others displayed in x and outcome in y
X=diabetes_dataset.drop(columns= 'Outcome',axis=1)
Y=diabetes_dataset['Outcome']

print(X)

print(Y)

"""Data Standardization"""

scaler=StandardScaler()

#scaler is a variable and StandardScaler is a function
scaler.fit(X)

standardized_data=scaler.transform(X)
#inconsistent data is made standard scaler.fit_transorm can do this 2 steps in one

print(standardized_data)

#all values will be more or less in same range
X=standardized_data
Y=diabetes_dataset['Outcome']

print(X)
print(Y)

"""Train Test Split"""

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=2)

#0.2 =80% training and 20%testing,stratify=Y same proportion spliting of dataset or all data may go to x-train or y_train itself
#ml model must not see test data Y_test is 0,1 for X_test
print(X.shape,X_train.shape,X_test.shape)

"""Training a model"""

classifier=svm.SVC(kernel='linear')

#training the support vector machine classifier
classifier.fit(X_train,Y_train)

"""Evaluate the model"""

#accuracy score on training data
X_train_prediction=classifier.predict(X_train)
training_data_accuracy=accuracy_score(X_train_prediction,Y_train)

print('Accuracy score of training data:', training_data_accuracy)

#accuracy score on test data now important step
X_test_prediction=classifier.predict(X_test)
test_data_accuracy=accuracy_score(X_test_prediction,Y_test)

print('Accuracy score of test data:', test_data_accuracy)

"""Making a predictive system"""

input_data=(8,183,64,0,0,23.3,0.672,32)
#random data from dataset
#changing ip data to numpy array
input_data_as_numpy_array=np.asarray(input_data)

#reshape the array as we are predicting for one instance(we trained on 768 ex and 8 cols)
#we are just using one data pt and model expects 768 ips so reshape for 1
input_data_reshaped=input_data_as_numpy_array.reshape(1,-1)
#we have standardize and now we are giving random data
#sso stand it again
# for streamlite std_data=scaler.transform(input_data_reshaped)
#print(std_data)
#prediction=classifier.predict(std_data)
prediction=classifier.predict(input_data_reshaped)

#as classifier has stored data
print(prediction)

if(prediction[0]==0):
  print("The person is not diabetic")
else:
    print("The person is diabetic")

#prediction is list and it has only 1 value so prediction[0]

"""Saving the model"""

import pickle

filename='trained_model.sav'
#opening file as trained_model.sav saved and as write binary wb
pickle.dump(classifier,open(filename,'wb'))

#loading the saved model
loaded_model=pickle.load(open('trained_model.sav','rb'))

#copy paste and replace classifier by loaded-model
input_data=(8,183,64,0,0,23.3,0.672,32)
#random data from dataset
#changing ip data to numpy array
input_data_as_numpy_array=np.asarray(input_data)

#reshape the array as we are predicting for one instance(we trained on 768 ex and 8 cols)
#we are just using one data pt and model expects 768 ips so reshape for 1
input_data_reshaped=input_data_as_numpy_array.reshape(1,-1)
#we have standardize and now we are giving random data
#sso stand it again
# for streamlite std_data=scaler.transform(input_data_reshaped)
#print(std_data)
#prediction=classifier.predict(std_data)
prediction=loaded_model.predict(input_data_reshaped)

#as classifier has stored data
print(prediction)

if(prediction[0]==0):
  print("The person is not diabetic")
else:
    print("The person is diabetic")

